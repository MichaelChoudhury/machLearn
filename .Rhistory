# console. Note that since there are no additional arguments
# to print(), you can leave off the parentheses after
# the function name. This is a convenient feature of the %>%
# operator.
cran %>%
select(ip_id, country, package, size) %>%
print
submit()
library(manipulate)
manipulate(plot(1:x), x = slider(1, 100))
library(manipulate)
myPlot <- function(s) {
plot(cars$dist - mean(cars$dist), cars$speed - mean(cars$speed))
abline(0, s)
}
abline(0, s)
myPlot
2
c
cars
manipulate(
plot(cars, xlim=c(0,x.max)),
x.max=slider(15,25))
manipulate(
barplot(as.matrix(longley[,factor]),
beside = TRUE, main = factor),
factor = picker("GNP", "Unemployed", "Employed"))
library(manipulate)
myPlot <- function(s) {
plot(cars$dist - mean(cars$dist), cars$speed - mean(cars$speed))
abline(0, s)
}
myPlot
manipulate(myPlot, s = slider(0, 2, step = 0.1))
manipulate(myPlot(s), s = slider(0, 2, step = 0.1))
manipulate(myPlot(s), x.s = slider(0, 2, step = 0.1))
manipulate(myPlot(s), slider = x(0, 2, step = 0.1))
manipulate(myPlot(s), s = slider(0, 2, step = 0.1))
library(manipulate)
manipulate(plot(1:x), x = slider(1, 100))
plot (3:x)
plot (3000:x)
plot (3:x)
plot(cars)
manipulate(
plot(cars, xlim=c(0,x.max)),
x.max=slider(15,25))
x.max=slider(10,25))
s
library(manipulate)
myPlot <- function(s) {
plot(cars$dist - mean(cars$dist), cars$speed - mean(cars$speed))
abline(0, s)
}
myPlot
manipulate(myPlot(s), s = slider(0, 2, step = 0.1))
library(manipulate)
myPlot <- function(s) {
plot(cars$dist - mean(cars$dist), cars$speed - mean(cars$speed))
abline(0, s)
manipulate(myPlot(s), s = slider(0, 2, step = 0.1))
}
library(manipulate)
myPlot <- function(s) {
plot(cars$dist - mean(cars$dist), cars$speed - mean(cars$speed))
abline(0, s)
manipulate(myPlot(s), s = slider(0, 2, step = 0.1))
}
s
manipulate(myPlot(s), s = slider(0, 2, step = 0.1))
library(manipulate)
myPlot <- function(s) {
plot(cars$dist - mean(cars$dist), cars$speed - mean(cars$speed))
abline(0, s)
}
manipulate(myPlot(s), s = slider(0, 2, step = 0.1))
myPlot
2
s
install.packages(rCharts)
install.packages("rCharts")
library(downloader)
download("http://github.com/ramnathv/rCharts/archive/master.tar.gz", "rCharts.tar.gz")
install.packages("rCharts.tar.gz", repos = NULL, type = "source")
require(devtools)
install_github('rCharts', 'ramnathv')
require(devtools)
install_github('rCharts', 'ramnathv')
getwd()
require(devtools)
install_github('rCharts', 'ramnathv')
gc()
Garbage collection 12 = 10+0+2 (level 0) ...
round(memory.limit()/2^20, 2)
model1 <- rpart(classe ~ ., data=subTraining, method="class")
# Predicting:
prediction1 <- predict(model1, subTesting, type = "class")
# Plot of the Decision Tree
rpart.plot(model1, main="Classification Tree", extra=102, under=TRUE, faclen=0)
library(rpart)
library(rpart.plot)
set.seed(1234)
trainingset<-trainingset[,colSums(is.na(trainingset)) == 0]
testingset <-testingset[,colSums(is.na(testingset)) == 0]
trainingset   <-trainingset[,-c(1:7)]
testingset <-testingset[,-c(1:7)]
subsamples <- createDataPartition(y=trainingset$classe, p=0.75, list=FALSE)
subTraining <- trainingset[subsamples, ]
subTesting <- trainingset[-subsamples, ]
plot(subTraining$classe, col="blue", main="Bar Plot of levels of the variable classe within the subTraining data set", xlab="classe levels", ylab="Frequency")
model1 <- rpart(classe ~ ., data=subTraining, method="class")
prediction1 <- predict(model1, subTesting, type = "class")
rpart.plot(model1, main="Classification Tree", extra=102, under=TRUE, faclen=0)
confusionMatrix(prediction1, subTesting$classe)
model2 <- randomForest(classe ~. , data=subTraining, method="class")
prediction2 <- predict(model2, subTesting, type = "class")
confusionMatrix(prediction2, subTesting$classe)
predictfinal <- predict(model2, testingset, type="class")
predictfinal
install.packages("caret")
install.packages("randomForest")
install.packages("rpart")
library(caret)
library(randomForest)
library(rpart)
library(rpart)
library(rpart.plot)
set.seed(1234)
trainUrl <- "http://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
testUrl <- "http://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
training <- read.csv(url(trainUrl), na.strings=c("NA","#DIV/0!",""))
testing <- read.csv(url(testUrl), na.strings=c("NA","#DIV/0!",""))
trainingset <-training
testingset <-testing
trainingset<-trainingset[,colSums(is.na(trainingset)) == 0]
testingset <-testingset[,colSums(is.na(testingset)) == 0]
trainingset   <-trainingset[,-c(1:7)]
testingset <-testingset[,-c(1:7)]
subsamples <- createDataPartition(y=trainingset$classe, p=0.75, list=FALSE)
subTraining <- trainingset[subsamples, ]
subTesting <- trainingset[-subsamples, ]
plot(subTraining$classe, col="blue", main="Bar Plot of levels of the variable classe within the subTraining data set", xlab="classe levels", ylab="Frequency")
model1 <- rpart(classe ~ ., data=subTraining, method="class")
prediction1 <- predict(model1, subTesting, type = "class")
rpart.plot(model1, main="Classification Tree", extra=102, under=TRUE, faclen=0)
confusionMatrix(prediction1, subTesting$classe)
model2 <- randomForest(classe ~. , data=subTraining, method="class")
prediction2 <- predict(model2, subTesting, type = "class")
confusionMatrix(prediction2, subTesting$classe)
predictfinal <- predict(model2, testingset, type="class")
predictfinal
q()
install.packages("caret")
install.packages("randomForest")
install.packages("rpart")
library(caret)
library(randomForest)
library(rpart)
library(rpart)
library(rpart.plot)
set.seed(1234)
trainUrl <- "http://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
testUrl <- "http://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
training <- read.csv(url(trainUrl), na.strings=c("NA","#DIV/0!",""))
testing <- read.csv(url(testUrl), na.strings=c("NA","#DIV/0!",""))
trainingset <-training
testingset <-testing
trainingset<-trainingset[,colSums(is.na(trainingset)) == 0]
testingset <-testingset[,colSums(is.na(testingset)) == 0]
trainingset   <-trainingset[,-c(1:7)]
testingset <-testingset[,-c(1:7)]
subsamples <- createDataPartition(y=trainingset$classe, p=0.75, list=FALSE)
subTraining <- trainingset[subsamples, ]
subTesting <- trainingset[-subsamples, ]
plot(subTraining$classe, col="blue", main="Bar Plot of levels of the variable classe within the
subTraining data set", xlab="classe levels", ylab="Frequency")
model1 <- rpart(classe ~ ., data=subTraining, method="class")
prediction1 <- predict(model1, subTesting, type = "class")
rpart.plot(model1, main="Classification Tree", extra=102, under=TRUE, faclen=0)
confusionMatrix(prediction1, subTesting$classe)
model2 <- randomForest(classe ~. , data=subTraining, method="class")
prediction2 <- predict(model2, subTesting, type = "class")
confusionMatrix(prediction2, subTesting$classe)
predictfinal <- predict(model2, testingset, type="class")
predictfinal
# Write files for submission
pml_write_files = function(x){
n = length(x)
for(i in 1:n){
filename = paste0("problem_id_",i,".txt")
write.table(x[i],file=filename,quote=FALSE,row.names=FALSE,col.names=FALSE)
}
}
pml_write_files(predictfinal)
predictfinal
install.packages("caret")
install.packages("randomForest")
install.packages("rpart")
library(caret)
library(randomForest)
library(rpart)
library(rpart)
library(rpart.plot)
set.seed(1234)
trainUrl <- "http://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
testUrl <- "http://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
training <- read.csv(url(trainUrl), na.strings=c("NA","#DIV/0!",""))
install.packages("caret")
install.packages("randomForest")
install.packages("rpart")
library(caret)
library(randomForest)
library(rpart)
library(rpart)
library(rpart.plot)
set.seed(1234)
trainUrl <- "http://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
testUrl <- "http://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
training <- read.csv(url(trainUrl), na.strings=c("NA","#DIV/0!",""))
```{r}
if (!require("caret")) {
install.packages("caret", repos="http://cran.rstudio.com/")
library("yaml")
}
```
```{r}
if (!require("caret")) {
install.packages("caret", repos="http://cran.rstudio.com/")
library("caret")
}
```
install.packages ("caret")
install.packages("caret")
if (!require("yaml")) {
install.packages("yaml", repos="http://cran.rstudio.com/")
library("yaml")
if (!require("caret")) {
install.packages("caret", repos="http://cran.rstudio.com/")
library("caret")
}
if (!require("yaml")) {
install.packages("yaml", repos="http://cran.rstudio.com/")
library("yaml")
if (!require("caret")) {
install.packages("caret", repos="http://cran.rstudio.com/")
library("caret")
}
plot(subTraining$classe, col="blue", main="Bar Plot of levels of the variable classe within the subTraining data set", xlab="classe levels", ylab="Frequency")
fancyRpartPlot(modFitA1)
fancyRpartPlot(modFitA1r
fancyRpartPlot(modFitA1)
fancyrpartPlot(modFitA1)
library (rpart.plot)
rpart.plot(model1, main="Classification Tree", extra=102, under=TRUE, faclen=0)
plot(subTraining$classe, col="blue", main="Bar Plot of levels of the variable classe within the
subTraining data set", xlab="classe levels", ylab="Frequency")
install.packages("caret")
install.packages("randomForest")
install.packages("rpart")
library(caret)
library(randomForest)
library(rpart)
library(rpart)
library(rpart.plot)
set.seed(1234)
trainUrl <- "http://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
testUrl <- "http://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
trainingset <- read.csv(url(trainUrl), na.strings=c("NA","#DIV/0!",""))
testingset <- read.csv(url(testUrl), na.strings=c("NA","#DIV/0!",""))
trainingset<-trainingset[,colSums(is.na(trainingset)) == 0]
testingset <-testingset[,colSums(is.na(testingset)) == 0]
trainingset   <-trainingset[,-c(1:7)]
testingset <-testingset[,-c(1:7)]
subsamples <- createDataPartition(y=trainingset$classe, p=0.75, list=FALSE)
subTraining <- trainingset[subsamples, ]
subTesting <- trainingset[-subsamples, ]
plot(subTraining$classe, col="blue", main="Bar Plot of levels of the variable classe within the
subTraining data set", xlab="classe levels", ylab="Frequency")
model1 <- rpart(classe ~ ., data=subTraining, method="class")
prediction1 <- predict(model1, subTesting, type = "class")
rpart.plot(model1, main="Classification Tree", extra=102, under=TRUE, faclen=0)
confusionMatrix(prediction1, subTesting$classe)
model2 <- randomForest(classe ~. , data=subTraining, method="class")
prediction2 <- predict(model2, subTesting, type = "class")
confusionMatrix(prediction2, subTesting$classe)
predictfinal <- predict(model2, testingset, type="class")
predictfinal
pml_write_files = function(x){
n = length(x)
for(i in 1:n){
filename = paste0("problem_id_",i,".txt")
write.table(x[i],file=filename,quote=FALSE,row.names=FALSE,col.names=FALSE)
}
}
pml_write_files(predictfinal)
install.packages("rpart")
rpart.plot(model1, main="Classification Tree", extra=102, under=TRUE, faclen=0)
rpart.plot(model1, main="Classification Tree", extra=102, under=TRUE, faclen=12)
rpart.plot(model1, main="Classification Tree", extra=102, under=TRUE, faclen=12)
rpart.plot(model1, main="Classification Tree", extra=102, under=TRUE, faclen=0)
rpart.plot(model1, main="Classification Tree", extra=10, under=TRUE, faclen=0)
rpart.plot(model1, main="Classification Tree", extra=102, under=FALSE, faclen=0)
rpart.plot(model1, main="Classification Tree", extra=102, under=FALSE, faclen=0, color="red")
rpart.plot(model1, main="Classification Tree", extra=102, under=FALSE, faclen=0)
fill = c("pink", "palegreen3")fill = c("pink", "palegreen3")fill = c("pink", "palegreen3")
rpart.plot(model1, main="Classification Tree", extra=10, under=TRUE, faclen=0, fill = c("pink", "palegreen3"))
rpart.plot(model1, main="Classification Tree", extra=10, under=TRUE, faclen=0, fill = c("pink", "palegreen3"))
rpart.plot(model1, main="Classification Tree", extra=2, under=TRUE, faclen=0, fill = c("pink", "palegreen3"))
rpart.plot(model1, main="Classification Tree", extra=102, under=FALSE, faclen=0)
rpart.plot(model1, main="Classification Tree", extra=2, under=FALSE, faclen=0)
rpart.plot(model1, main="Classification Tree", extra=2, under=FALSE, faclen=0)
rpart.plot(model1, main="Classification Tree", extra=2, under=FALSE, faclen=0, TYPE=4)
rpart.plot(model1, main="Classification Tree", extra=2, under=FALSE, faclen=0, type=4)
,
rpart.plot(model1, main="Classification Tree", extra=2, under=FALSE, faclen=0, type=4, extra=2)
rpart.plot(model1, main="Classification Tree", extra=2, under=FALSE, faclen=0, type=4, varlen=0)
rpart.plot(model1, main="Classification Tree", extra=2, under=FALSE, faclen=0, type=4, varlen=0)
rpart.plot(model1, main="Classification Tree", extra=2, under=FALSE, faclen=0, box.col="red")
rpart.plot(model1, main="Classification Tree", extra=2, under=FALSE, faclen=0, box.col="blue")
rpart.plot(model1, main="Classification Tree", extra=2, under=FALSE, faclen=0, box.col="blue", border.col="red")
rpart.plot(model1, main="Classification Tree", extra=2, under=FALSE, faclen=0, box.col="blue", border.col="red", type=4)
rpart.plot(model1, main="Classification Tree", extra=2, under=FALSE, faclen=0, box.col="blue", border.col="red", type=3)
rpart.plot(model1, main="Classification Tree", extra=2, under=FALSE, faclen=0, box.col="blue", border.col="red", type=2)
rpart.plot(model1, main="Classification Tree", extra=2, under=FALSE, faclen=0, box.col="blue", border.col="red", type=1)
rpart.plot(model1, main="Classification Tree", extra=2, under=FALSE, faclen=0, box.col="blue", border.col="red", type=0)
rpart.plot(model1, main="Classification Tree", extra=2, under=FALSE, faclen=0, box.col="blue", border.col="red", type=0, extra=9)
rpart.plot(model1, main="Classification Tree", extra=2, under=FALSE, faclen=0, box.col="blue", border.col="red", type=0, extra=3)
rpart.plot(model1, main="Classification Tree", extra=2, under=FALSE, faclen=0, box.col="blue", border.col="red", type=0)
rpart.plot(model1, main="Classification Tree", extra=2, under=FALSE, faclen=0, box.col="blue", border.col="red", type=0, tweak=4)
rpart.plot(model1, main="Classification Tree", extra=2, under=FALSE, faclen=0, box.col="blue", border.col="red", type=0, tweak=4)
rpart.plot(model1, main="Classification Tree", extra=2, under=FALSE, faclen=0, box.col="blue", border.col="red", type=0, tweak=2)
rpart.plot(model1, main="Classification Tree", extra=2, under=FALSE, faclen=0, box.col="blue", border.col="red", type=0, tweak=1)
rpart.plot(model1, main="Classification Tree", extra=2, under=FALSE, faclen=0, box.col="blue", border.col="white", type=0, tweak=1)
rpart.plot(model1, main="Classification Tree", extra=2, under=FALSE, faclen=0, box.col="white", border.col="red", type=0, tweak=1)
rpart.plot(model1, main="Classification Tree", extra=2, under=FALSE, faclen=0, box.col="yellow", border.col="red", type=0, tweak=1)
rpart.plot(model1, main="Classification Tree", extra=2, under=FALSE, faclen=0, box.col="yellow", border.col="red", type=0, tweak=1,branch.lty=2)
rpart.plot(model1, main="Classification Tree", extra=2, under=FALSE, faclen=0, box.col="yellow", border.col="red", type=0, tweak=1,branch.lty=2)
rpart.plot(model1, main="Classification Tree", extra=2, under=FALSE, faclen=0, box.col="yellow", border.col="red", type=0, tweak=1,branch.lty=3)
rpart.plot(model1, main="Classification Tree", extra=2, under=FALSE, faclen=0, box.col="yellow", border.col="red", type=0, tweak=1,branch.lty=4)
rpart.plot(model1, main="Classification Tree", extra=2, under=FALSE, faclen=0, box.col="yellow", border.col="red", type=0, tweak=1,branch.lty=2)
rpart.plot(model1, main="Classification Tree", extra=2, under=FALSE, faclen=0, box.col="yellow", border.col="red", type=0, tweak=1,branch.lty=4)
rpart.plot(model1, main="Classification Tree", extra=2, under=FALSE, faclen=0, box.col="yellow", border.col="red", type=0, tweak=1,branch.lty=3)
rpart.plot(model1, main="Classification Tree", extra=2, under=FALSE, faclen=0, box.col="yellow", border.col="red", type=0, tweak=1,branch.lty=3,branch.col="green")
rpart.plot(model1, main="Classification Tree", extra=2, under=FALSE, faclen=0, box.col="yellow", border.col="red", type=0, tweak=1,branch.lty=2,branch.col="green")
rpart.plot(model1, main="Classification Tree", extra=2, under=FALSE, faclen=0, box.col="yellow", border.col="red", type=0, tweak=1,branch.lty=1,branch.col="green")
rpart.plot(model1, main="Classification Tree", extra=2, under=FALSE, faclen=0, box.col="yellow", border.col="red", type=0, tweak=1,branch.lty=1,branch.col="green")
rpart.plot(model1, main="Classification Tree", extra=2, under=FALSE, faclen=0,
box.col="yellow", border.col="red", type=0, tweak=1,branch.lty=1,branch.col="green")
rpart.plot(model1, main="Classification Tree", extra=2, under=FALSE, faclen=0,
box.col="yellow", border.col="red", type=0, tweak=1,branch.lty=1,branch.col="green")
plot(subTraining$classe, col="blue", main="Bar Plot of levels of the variable classe within the subTraining data set", xlab="classe levels", ylab="Frequency")
plot(subTraining$classe, col="green", main="Plot of levels of the variable "classe" within the subTraining data set", xlab="classe levels", ylab="Frequency")
plot(subTraining$classe, col="green", main="Plot of levels of the variable classe within the subTraining data set", xlab="classe levels", ylab="Frequency")
plot(subTraining$classe, col="yellow", main="Plot of levels of the variable classe within the subTraining data set", xlab="classe levels", ylab="Frequency")
plot(subTraining$classe, col="yellow", main="Plot of the levels of the outcome variable - classe - within the training data set", xlab="Levels", ylab="No of occurrences")
plot(subTraining$classe, col="yellow", main="Outcome Variable - classe", xlab="Levels", ylab="No of occurrences")
plot(subTraining$classe, col="yellow", main="Outcome variable - classe", xlab="Levels", ylab="No of occurrences")
plot(subTraining$classe, col="yellow", main="Outcome variable - 'classe'", xlab="Levels", ylab="No of occurrences")
plot(subTraining$classe, col="yellow", main="Distribution of outcome variable - 'classe'", xlab="Levels", ylab="No of occurrences")
plot(subTraining$classe, col="yellow", main="Distribution of outcome variable - 'classe'", xlab="Factor levels", ylab="No of occurrences")
hist(w1$vals)
> hist(w1$vals,main="Distribution of w1",xlab="w1")
hist(w1$vals)
> hist(subTraining$classe,main="Distribution of w1",xlab="w1")
hist(w1$vals)
> hist(subTraining$classe,main="Distribution of w1",xlab="w1")
hist(subTraining$classe,main="Distribution of w1",xlab="w1")
hist(w1$vals)
> hist(subTraining$classe)
hist(w1$vals)
> hist(subTraining$classe)
hist(subTraining$classe)
plot(subTraining$classe)
hist(subTraining$classe)
barplot(subTraining$classe)
plot(subTraining$classe)
plot(subTraining$classe, pch=16)
plot(subTraining$classe, pch=16, color="red")
plot(subTraining$classe, pch=16, col="red")
plot(subTraining$classe, pch=16, col="perple")
plot(subTraining$classe, pch=16, col="purple")
plot(subTraining$classe, pch=16, col="navy")
plot(subTraining$classe, col="yellow", main="Distribution of outcome variable - 'classe'", xlab="Factor levels", ylab="No of occurrences", col="navy")
plot(subTraining$classe, col="navy", main="Distribution of outcome variable - 'classe'", xlab="Factor levels", ylab="No of occurrences", ")
plot(subTraining$classe, col="navy", main="Distribution of outcome variable - 'classe'", xlab="Factor levels", ylab="No of occurrences", ")
plot(subTraining$classe, col="navy", main="Distribution of outcome variable - 'classe'", xlab="Factor levels", ylab="No of occurrences")
plot(subTraining$classe, col="navy", main="Distribution of outcome variable - 'classe'", xlab="Factor levels", ylab="No of occurrences", lwd=.5)
plot(subTraining$classe, col="navy", main="Distribution of outcome variable - 'classe'", xlab="Factor levels", ylab="No of occurrences", lwd=3)
plot(subTraining$classe, col="navy", main="Distribution of outcome variable - 'classe'", xlab="Factor levels", ylab="No of occurrences")
plot(subTraining$classe, col="navy", main="Distribution of outcome variable - 'classe'", xlab="Factor levels", ylab="No of occurrences")
plot(subTraining$classe, col=21, main="Distribution of outcome variable - 'classe'", xlab="Factor levels", ylab="No of occurrences")
plot(subTraining$classe, col=4, main="Distribution of outcome variable - 'classe'", xlab="Factor levels", ylab="No of occurrences")
plot(subTraining$classe, col=4, main="Distribution of outcome variable - 'classe'", xlab="Factor levels", ylab="No of occurrences", pin=6,6)
plot(subTraining$classe, col=4, main="Distribution of outcome variable - 'classe'", xlab="Factor levels", ylab="No of occurrences", pin=6)
plot(subTraining$classe, col=4, main="Distribution of outcome variable - 'classe'", xlab="Factor levels", ylab="No of occurrences", pin=6)
plot(subTraining$classe, col="navy", main="Distribution of outcome variable - 'classe'", xlab="Factor levels", ylab="No of occurrences")
odFitA1 <- rpart(classe ~ ., data=myTraining, method="class")
odFitA1 <- rpart(classe ~ ., data=subTraining, method="class")
fancyRpartPlot(modFitA1)
library(rpart)
library(rpart.plot)
library(RColorBrewer)
library(rattle)
library(rpart.plot)
library(RColorBrewer)
library(rattle)
fancyRpartPlot(modFitA1)
fancyRpartPlot(modFitA1)
install.packages ("rattle)")
install.packages ("rattle)")
library (rattle)
install.packages ("rattle)")
install.packages ("rattle)")
plot(subTraining$classe, col="navy", main="Distribution of outcome variable - 'classe'", xlab="Factor levels", ylab="No of occurrences, plot(subTraining$classe, col="navy", main="Distribution of outcome variable - 'classe'", xlab="Factor levels", ylab="No of occurrences")")
plot(subTraining$classe, col="navy", main="Distribution of outcome variable - 'classe'", xlab="Factor levels", ylab="No of occurrences, plot(subTraining$classe, col="navy", main="Distribution of outcome variable - 'classe'", xlab="Factor levels", ylab="No of occurrences")")
plot(subTraining$classe, col="navy", main="Distribution of outcome variable - 'classe'", xlab="Factor levels", ylab="No of occurrences, plot(subTraining$classe, col="navy", main="Distribution of outcome variable - 'classe'", xlab="Factor levels", ylab="No of occurrences")")
plot(subTraining$classe, col="navy", main="Distribution of outcome variable - 'classe'", xlab="Factor levels", ylab="No of occurrences")
plot(subTraining$classe, col="navy", main="Distribution of outcome variable - 'classe'", xlab="Factor levels", ylab="No of occurrences")
plot(subTraining$classe, col="navy", bg="yellow",main="Distribution of outcome variable - 'classe'", xlab="Factor levels", ylab="No of occurrences")
plot(subTraining$classe, col="navy", bg="yellow",main="Distribution of outcome variable - 'classe'", xlab="Factor levels", ylab="No of occurrences")
plot(subTraining$classe, col="navy", bg="yellow",main="Distribution of outcome variable - 'classe'", xlab="Factor levels", ylab="No of occurrences, par(bg = "lightyellow")")
par(bg = "lightyellow")
plot(subTraining$classe, col="navy", main="Distribution of outcome variable - 'classe'", xlab="Factor levels", ylab="No of occurrences")
legend("bottomright", c("CCI", "QMACRO", "QMICRO"),
+ lty = c(1, 2, 3), col = c("black", "red",
+ "blue"))
legend("bottomright", c("CCI", "QMACRO", "QMICRO"),
+ lty = c(1, 2, 3), col = c("black", "red",
+ "blue"))
plot(subTraining$classe, col="navy", main="Distribution of outcome variable - 'classe'", xlab="Factor levels", ylab="No of occurrences", type=h)
plot(subTraining$classe, col="navy", main="Distribution of outcome variable - 'classe'", xlab="Factor levels", ylab="No of occurrences", type=h)
plot(subTraining$classe, col="navy", main="Distribution of outcome variable - 'classe'", xlab="Factor levels", ylab="No of occurrences", type=1)
plot(subTraining$classe, col="navy", main="Distribution of outcome variable - 'classe'", xlab="Factor levels", ylab="No of occurrences", type=1)
par(bg = "lightyellow")
plot(subTraining$classe, col="lightgreen", main="Distribution of outcome variable - 'classe'", xlab="Factor levels", ylab="No of occurrences")
par(bg = "lightred")
plot(subTraining$classe, col="lightgreen", main="Distribution of outcome variable - 'classe'", xlab="Factor levels", ylab="No of occurrences")
par(bg = "lightblue")
plot(subTraining$classe, col="lightgreen", main="Distribution of outcome variable - 'classe'", xlab="Factor levels", ylab="No of occurrences")
par(bg = "lightblue")
plot(subTraining$classe, col="lightgreen", main="Distribution of outcome variable - 'classe'", xlab="Factor levels", ylab="No of occurrences")
par(bg = "lightblue")
plot(subTraining$classe, col="lightgreen", main="Distribution of outcome variable - 'classe'", xlab="Factor levels", ylab="No of occurrences")
model1 <- rpart(classe ~ ., data=subTraining, method="class")
prediction1 <- predict(model1, subTesting, type = "class")
rpart.plot(model1, main="Model A - Classification Decision Tree", extra=2, under=FALSE, faclen=0,
box.col="yellow", border.col="red", type=0, tweak=1,branch.lty=1,branch.col="green")
model1 <- rpart(classe ~ ., data=subTraining, method="class")
prediction1 <- predict(model1, subTesting, type = "class")
par(bg = "lightgrey")
rpart.plot(model1, main="Model A - Classification Decision Tree", extra=2, under=FALSE, faclen=0,
box.col="yellow", border.col="red", type=0, tweak=1,branch.lty=1,branch.col="green")
confusionMatrix(prediction1, subTesting$classe)
model1 <- rpart(classe ~ ., data=subTraining, method="class")
prediction1 <- predict(model1, subTesting, type = "class")
par(bg = "white")
rpart.plot(model1, main="Model A - Classification Decision Tree", extra=2, under=FALSE, faclen=0,
box.col="yellow", border.col="red", type=0, tweak=1,branch.lty=1,branch.col="green")
confusionMatrix(prediction1, subTesting$classe)
par(bg = "white")
rpart.plot(model1, main="Model A - Classification Decision Tree", extra=2, under=FALSE, faclen=0,
box.col="yellow", border.col="red", type=0, tweak=1,branch.lty=1,branch.col="green")
par(bg = "lightblue")
plot(subTraining$classe, col="lightgreen", main="Distribution of outcome variable - 'classe'", xlab="Factor levels", ylab="No of occurrences")
legend("bottomright")
legend("bottomright")
legend("bottomright", c("CCI", "QMACRO", "QMICRO"),
+ lty = c(1, 2, 3), col = c("black", "red",
+ "blue"))
legend("bottomright", c("CCI", "QMACRO", "QMICRO"),
ty = c(1, 2, 3), col = c("black", "red",
"blue"))
barplot(subTraining$classe, col = rainbow(20), space=10)
plot(subTraining$classe, col = rainbow(20), space=10)
par(bg = "lightblue")
plot(plot(subTraining$classe, col = rainbow(20), space=10), col="lightgreen", main="Distribution of outcome variable - 'classe'", xlab="Factor levels", ylab="No of occurrences")
plot(subTraining$classe, col = rainbow(20), space=10)
plot(subTraining$classe, col = rainbow(20), space=10,main="Distribution of outcome variable - 'classe'", xlab="Factor levels", ylab="No of occurrences")
par(bg = "lightblue")
plot(subTraining$classe, col = rainbow(20), space=10,main="Distribution of outcome variable - 'classe'", xlab="Factor levels", ylab="No of occurrences")
par(bg = "white")
rpart.plot(model1, main="Model A - Classification Decision Tree", extra=2, under=FALSE, faclen=0,
box.col="yellow", border.col="red", type=0, tweak=1,branch.lty=1,branch.col="green")
model2 <- randomForest(classe ~. , data=subTraining, method="class")
model2 <- randomForest(classe ~. , data=subTraining, method="class")
prediction2 <- predict(model2, subTesting, type = "class")
confusionMatrix(prediction2, subTesting$classe)
model2 <- randomForest(classe ~. , data=subTraining, method="class")
prediction2 <- predict(model2, subTesting, type = "class")
confusionMatrix(prediction2, subTesting$classe)
predictfinal <- predict(model2, testingset, type="class")
predictfinal
pml_write_files = function(x){
n = length(x)
for(i in 1:n){
filename = paste0("problem_id_",i,".txt")
write.table(x[i],file=filename,quote=FALSE,row.names=FALSE,col.names=FALSE)
}
}
pml_write_files(predictfinal)
The key variable is "classe" which is a factor with five levels:
<br>
Class A - exactly according to the specification <br>
Class B - throwing the elbows to the front <br>
Class C - lifting the dumbbell only halfway <br>
Class D - lowering the dumbbell only halfway <br>
Class E - throwing the hips to the front <br>
getwd()
setwd(C:\MJC\Coursera\Machine Learning\Project)
setwd(C:/MJC/Coursera/Machine Learning/Project)
setwd("C:/MJC/Coursera/Machine Learning/Project")
getwd()
